{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4941a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前路径 -  /Users/ruijie/Desktop/github/pytorch-prev/class7加载数据集\n"
     ]
    }
   ],
   "source": [
    "# 环境配置\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedShuffleSplit,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"当前路径 -  %s\" %os.getcwd())\n",
    "# os.chdir(\"./\") #改变路径\n",
    "\n",
    "cvSFS= StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=100)\n",
    "# 文件处理\n",
    "CRCtrain=pd.read_excel(\"../data/IBD血液原始数据_副本.xlsx\",sheet_name=\"train\")#导入数据\n",
    "CRCtrain['ill'].unique()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# XGBoost 分类\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #显示中文\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "## 分类编码处理\n",
    "#codes 方法返回每个分类的整数编码。\n",
    "#这些编码是从 0 开始分配的，表示每个不同的分类。\n",
    "#例如，如果 '对照' 列包含三个不同的分类：'A', 'B', 'C'，则 'A' 的编码为 0，'B' 的编码为 1，'C' 的编码为 2。\n",
    "\n",
    "CRCtrain['ill'] = pd.Categorical(CRCtrain['ill']).codes \n",
    "#将 '对照' 列转换为整数编码，并将结果存储回 '对照' 列。CRC2['类别'] = pd.Categorical(IBD_2['类别']).codes\n",
    "#提取特征列\n",
    "CRCtrainX=CRCtrain.iloc[:,0:54] ##定义x\n",
    "#提取标签列 \n",
    "CRCtrainY=CRCtrain.iloc[:,54]##定义标签\n",
    "# 测试集数据\n",
    "CRCtest=pd.read_excel(\"../data/IBD血液原始数据_副本.xlsx\",sheet_name=\"test\")#导入数据\n",
    "#codes 方法返回每个分类的整数编码。\n",
    "#这些编码是从 0 开始分配的，表示每个不同的分类。\n",
    "#例如，如果 '对照' 列包含三个不同的分类：'A', 'B', 'C'，则 'A' 的编码为 0，'B' 的编码为 1，'C' 的编码为 2。\n",
    "\n",
    "CRCtest['ill'] = pd.Categorical(CRCtest['ill']).codes \n",
    "#将 '对照' 列转换为整数编码，并将结果存储回 '对照' 列。CRC2['类别'] = pd.Categorical(IBD_2['类别']).codes\n",
    "#提取特征列\n",
    "CRCtestX=CRCtest.iloc[:,0:54] ##定义x\n",
    "#提取标签列\n",
    "CRCtestY=CRCtest.iloc[:,54]##定义标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b900b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率=0.6083333333333333\n",
      "recall=0.3555555555555555\n",
      "准确率=0.5577777777777777\n",
      "roc_auc=0.6325925925925926\n",
      "precision0.45519480519480526\n",
      "F1值率0.5881780719280719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# pip install xgboost \n",
    "import xgboost as xgb\n",
    "\n",
    "xgb.__version__\n",
    "## XGBClassifier (未调参)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#模型训练\n",
    "clfXGB=XGBClassifier(random_state=200)\n",
    "#分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(CRCtrainX,CRCtrainY,test_size=0.2,random_state=100)\n",
    "#在使用 ShuffleSplit 进行交叉验证时，通常需要指定 test_size 或 train_size，其中至少一个必须是非空的。\n",
    "\n",
    "#例如，如果指定 test_size=0.3，则将数据集划分为 70% 的训练集和 30% 的测试集。\n",
    "\n",
    "#每次迭代时，ShuffleSplit 都会重新随机重排数据集，并将其划分为训练集和测试集。\n",
    "\n",
    "#最后，可以通过计算多个迭代的平均性能，来评估模型的泛化能力和稳定性。\n",
    "\n",
    "# StratifiedShuffleSplit 是一种交叉验证策略，用于将数据集划分为训练集和测试集。与 ShuffleSplit 类似，StratifiedShuffleSplit 也是通过对数据集进行随机重排，然后将数据集划分为多个训练集和测试集，以测试模型在不同的训练集和测试集上的性能。不同之处在于 StratifiedShuffleSplit 会保证每个划分中，训练集和测试集中的类别分布是一致的，从而避免了因类别分布不均衡而导致的模型偏差或方差问题。\n",
    "\n",
    "# sklearn.metrics.SCORERS.keys()返回一个包含所有可用的scoring函数名称的列表。这些名称可以作为scoring参数传递给cross_val_score()和GridSearchCV()等函数\n",
    "# from sklearn.metrics import SCORERS\n",
    "\n",
    "# print(SCORERS.keys())\n",
    "\n",
    "# 'accuracy'：准确率；\n",
    "# \n",
    "# 'balanced_accuracy'：平衡准确率；\n",
    "# \n",
    "# 'top_k_accuracy'：top_k准确率，k可以通过参数进行设置；\n",
    "# \n",
    "# 'average_precision'：平均准确率；\n",
    "# \n",
    "# 'neg_brier_score'：负Brier分数；\n",
    "# \n",
    "# 'f1'：F1分数，综合考虑了精确率和召回率；\n",
    "# \n",
    "# 'f1_micro'：微平均F1分数；\n",
    "# \n",
    "# 'f1_macro'：宏平均F1分数；\n",
    "# \n",
    "# 'f1_weighted'：加权平均F1分数，按照样本数量加权；\n",
    "# \n",
    "# 'f1_samples'：样本平均F1分数，针对多标签分类；\n",
    "# \n",
    "# 'neg_log_loss'：负对数似然损失，适用于概率模型；\n",
    "# \n",
    "# 'precision'：精确率；\n",
    "# \n",
    "# 'recall'：召回率；\n",
    "# \n",
    "# 'roc_auc'：ROC曲线下的面积；\n",
    "# \n",
    "# 'roc_auc_ovo'：多类别ROC曲线下的面积（一对多）；\n",
    "# \n",
    "# 'roc_auc_ovr'：多类别ROC曲线下的面积（一对剩余）；\n",
    "# \n",
    "# 'balanced_accuracy'：平衡准确率。\n",
    "# \n",
    "# 需要注意的是，有些指标是多类别分类特有的，例如roc_auc_ovo和roc_auc_ovr，可以处理多类别分类的问题。\n",
    "\n",
    "clfXGB.fit(CRCtrainX,CRCtrainY)\n",
    "# 预测概率\n",
    "CRCtrainY_prob = clfXGB.predict_proba(CRCtrainX)[:, 1]\n",
    "\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#balanced accuracy\n",
    "print('准确率={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='balanced_accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('roc_auc={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "\n",
    "print('F1值率{}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='f1_weighted',cv=cvSFS).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0787d704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:51<00:00,  1.12s/trial, best loss: 0.5]\n",
      "准确率=0.6166666666666666\n",
      "roc_auc=0.6355555555555555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 调参\n",
    "import hyperopt\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, partial, tpe\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    clf=XGBClassifier(n_estimators= int(params['n_estimators']),#以字典的结构传入，int：参数取值为整数\n",
    "                      learning_rate=int(params['learning_rate']),\n",
    "                      max_depth=int(params['max_depth']),                   \n",
    "                      random_state=100)#不需要调的就直接输入固定值  \n",
    "     \n",
    "    cv=StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=100)#定义交叉验证\n",
    "    \n",
    "    res = cross_val_score(clf,                                        \n",
    "                          CRCtrainX,CRCtrainY, #输入交叉验证训练样本 \n",
    "                          scoring='roc_auc',\n",
    "                          cv=cv,\n",
    "                          #error_score=\"raise\",\n",
    "                          ).mean() #如果交叉验证中算法执行报错，告诉错误理由\n",
    "    \n",
    "\n",
    "    return res \n",
    " \n",
    "spaces = {\"n_estimators\": hp.quniform(\"n_estimators\",25,500,25),#均匀分布的浮点数\n",
    "          \"max_depth\": hp.quniform(\"max_depth\", 1, 10,2),\n",
    "          \"learning_rate\": hp.quniform(\"learning_rate\",0.1,1,0.1)}\n",
    "         \n",
    "                                        \n",
    "\n",
    "#保存送代过程\n",
    "trials=Trials()\n",
    "\n",
    "#设置提前停止\n",
    "early_stop_fn=no_progress_loss(100)  #连续100次损失函数没有下降，就停止模型\n",
    "\n",
    "#定义代理模型\n",
    "params_best2=fmin(hyperopt_objective,\n",
    "                    space=spaces,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=100,\n",
    "                    verbose=True,\n",
    "                    trials=trials,\n",
    "                    early_stop_fn=early_stop_fn,\n",
    "                    rstate=np.random.default_rng(100)#稳定优化参数结果\n",
    "                )     \n",
    "#报错代码段：rstate=RandomState(seed),解决方案：rstate=np.random.default_rng(seed),问题根源：版本问题\n",
    "\n",
    "params_best2\n",
    "\n",
    "clfXGB=XGBClassifier(learning_rate=0.6, max_depth=4, n_estimators=450, random_state=200)\n",
    "clfXGB\n",
    "print('准确率={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "\n",
    "print('roc_auc={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e5c056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruijie/.virtualenvs/pytorch-prev-qP6jJXPo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(XGBmodel)\n\u001b[1;32m     10\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer(CRCtrainX)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplots\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_display\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m shap\u001b[38;5;241m.\u001b[39mplots\u001b[38;5;241m.\u001b[39mbar(shap_values\u001b[38;5;241m.\u001b[39mcohorts(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mabs\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     15\u001b[0m shap\u001b[38;5;241m.\u001b[39mplots\u001b[38;5;241m.\u001b[39mheatmap(shap_values[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m100\u001b[39m])\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch-prev-qP6jJXPo/lib/python3.10/site-packages/shap/plots/_bar.py:260\u001b[0m, in \u001b[0;36mbar\u001b[0;34m(shap_values, max_display, order, clustering, clustering_cutoff, show_data, ax, show)\u001b[0m\n\u001b[1;32m    252\u001b[0m     ax\u001b[38;5;241m.\u001b[39mbarh(\n\u001b[1;32m    253\u001b[0m         y_pos \u001b[38;5;241m+\u001b[39m ypos_offset, values[i,feature_inds],\n\u001b[1;32m    254\u001b[0m         bar_width, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    255\u001b[0m         color\u001b[38;5;241m=\u001b[39m[colors\u001b[38;5;241m.\u001b[39mblue_rgb \u001b[38;5;28;01mif\u001b[39;00m values[i,feature_inds[j]] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m colors\u001b[38;5;241m.\u001b[39mred_rgb \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pos))],\n\u001b[1;32m    256\u001b[0m         hatch\u001b[38;5;241m=\u001b[39mpatterns[i], edgecolor\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0.8\u001b[39m), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcohort_labels[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcohort_sizes[i]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(cohort_sizes)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# draw the yticks (the 1e-8 is so matplotlib 3.3 doesn't try and collapse the ticks)\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_yticks(\u001b[38;5;28mlist\u001b[39m(y_pos) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(y_pos \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m), yticklabels \u001b[38;5;241m+\u001b[39m [t\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m yticklabels], fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n\u001b[1;32m    262\u001b[0m xlen \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mget_xlim()[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m ax\u001b[38;5;241m.\u001b[39mget_xlim()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m#xticks = ax.get_xticks()\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pytorch-prev-qP6jJXPo/lib/python3.10/site-packages/shap/plots/_bar.py:260\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    252\u001b[0m     ax\u001b[38;5;241m.\u001b[39mbarh(\n\u001b[1;32m    253\u001b[0m         y_pos \u001b[38;5;241m+\u001b[39m ypos_offset, values[i,feature_inds],\n\u001b[1;32m    254\u001b[0m         bar_width, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    255\u001b[0m         color\u001b[38;5;241m=\u001b[39m[colors\u001b[38;5;241m.\u001b[39mblue_rgb \u001b[38;5;28;01mif\u001b[39;00m values[i,feature_inds[j]] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m colors\u001b[38;5;241m.\u001b[39mred_rgb \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pos))],\n\u001b[1;32m    256\u001b[0m         hatch\u001b[38;5;241m=\u001b[39mpatterns[i], edgecolor\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0.8\u001b[39m), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcohort_labels[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcohort_sizes[i]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(cohort_sizes)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# draw the yticks (the 1e-8 is so matplotlib 3.3 doesn't try and collapse the ticks)\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_yticks(\u001b[38;5;28mlist\u001b[39m(y_pos) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(y_pos \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m), yticklabels \u001b[38;5;241m+\u001b[39m [\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m yticklabels], fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n\u001b[1;32m    262\u001b[0m xlen \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mget_xlim()[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m ax\u001b[38;5;241m.\u001b[39mget_xlim()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m#xticks = ax.get_xticks()\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'split'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApcAAAIeCAYAAADu0ySBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdzUlEQVR4nO3dfWxddf3A8U9Z6cWVtq6UMnB16xDQRQdCJhPFR1SEKaIooFFBGYgsEh+IGUYJahhRASVsomMCUSEqASbxCeIQJRkSCRRwgNncoIwRVjbajmHH3Pn9Qai/ssd2n+7cu71eyf3jXs45/eTrN/Ode09764qiKAIAABLsVfYAAADsPsQlAABpxCUAAGnEJQAAacQlAABpxCUAAGnEJQAAacQlAABp6sseICJi06ZN8dRTT0VTU1PU1dWVPQ4AAK9QFEX09/fHQQcdFHvttfX3J6siLp966qno6OgoewwAALaju7s7JkyYsNX/XhVx2dTUFBEvDdvc3FzyNAAAvFJfX190dHQMdtvWVEVcvvxReHNzs7gEAKhi27uF0S/0AACQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJCmvuwBhli1JmLdxrKnYE/SWIloaSx7CgDYbVRXXM6aH9HdV/YU7Ck62yMWnCcuASBRdcXlip6IpavLngIAgBFyzyUAAGnEJQAAacQlAABpxCUAAGnEJQAAacQlAABpxCUAAGnEJQAAacQlAABphh2XPT090dnZGStWrBh87eGHH45p06bFuHHj4oILLoiiKDJnBACgRgwrLnt6emLGjBlDwnJgYCA+9KEPxVFHHRX/+Mc/YsmSJXHdddcljwkAQC0YVlyedtpp8clPfnLIa3/4wx+it7c3Lr/88jj44IPjkksuiQULFqQOCQBAbagfzsHz58+Pzs7OOP/88wdf6+rqiunTp8fYsWMjImLq1KmxZMmSbV5nYGAgBgYGBp/39fUNZwwAAKrUsN657Ozs3Oy1vr6+Ia/X1dXFmDFjYu3atVu9zpw5c6KlpWXw0dHRMZwxAACoUjv92+L19fVRqVSGvLbPPvvE+vXrt3rO7Nmzo7e3d/DR3d29s2MAAFAFhvWx+Ja0trbGww8/POS1/v7+aGho2Oo5lUplsyAFAKD27fQ7l9OmTYvFixcPPl++fHkMDAxEa2vrzl4aAIAas9Nx+Y53vCP6+vri2muvjYiISy65JI477rgYM2bMTg8HAEBt2emPxevr6+Oaa66J008/PS644ILYa6+94i9/+UvCaAAA1JoRxeUrv4Hnwx/+cCxbtizuu+++mD59euy3334pwwEAUFt2+p3Ll40fPz5OPPHErMsBAFCDdvqeSwAAeJm4BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAIE3a37lMMaktYkxD2VOwp+hsL3sCANjtVFdcXjUzoqm57CnYkzRWyp4AAHYr1RWXB7ZGNItLAIBa5Z5LAADSiEsAANKISwAA0ohLAADSiEsAANKISwAA0ohLAADSiEsAANKISwAA0ohLAADSiEsAANKISwAA0tSXPcAQq9ZErNtY9hRsTWMloqWx7CkAgCpWXXE5a35Ed1/ZU7Alne0RC84TlwDANlVXXK7oiVi6uuwpAAAYIfdcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJCmvuwBhpjUFjGmoewp2JLO9rInAABqQHXF5VUzI5qay56CrWmslD0BAFDlqisuD2yNaBaXAAC1yj2XAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApKkve4AhVq2JWLex7Cn2DI2ViJbGsqcAAHYz1RWXs+ZHdPeVPcXur7M9YsF54hIASFddcbmiJ2Lp6rKnAABghNxzCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQJq0uLzmmmuio6Mjxo4dG+9617vi3//+d9alAQCoESlxuWzZsvj2t78dCxcujEcffTQOPvjgOOOMMzIuDQBADUmJy/vvvz+mT58eRx55ZLz2ta+Nz33uc7F06dKMSwMAUENS4nLKlCmxaNGieOCBB6K3tzfmzZsX73vf+zIuDQBADanPuMiUKVPilFNOiTe/+c0REdHZ2Rl///vft3r8wMBADAwMDD7v6+vLGAMAgJKlvHN57733xm233Rb33HNPPPfcc3H66afHCSecEEVRbPH4OXPmREtLy+Cjo6MjYwwAAEqWEpc33nhjnHbaaXH00UdHS0tLfPe7341ly5ZFV1fXFo+fPXt29Pb2Dj66u7szxgAAoGQpH4tv2rQpenp6Bp/39/fH+vXr47///e8Wj69UKlGpVDJ+NAAAVSQlLo899tj47Gc/G0ceeWQccMABcc0118T48eNj6tSpGZcHAKBGpMTlxz72sXjkkUfihz/8YaxatSre+MY3xi233BJ77713xuUBAKgRKXFZV1cX3/zmN+Ob3/xmxuUAAKhRvlscAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANCnf0JNmUlvEmIayp9j9dbaXPQEAsJuqrri8amZEU3PZU+wZGitlTwAA7IaqKy4PbI1oFpcAALXKPZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkqS97gCFWrYlYt7HsKWpLYyWipbHsKQAAIqLa4nLW/IjuvrKnqB2d7RELzhOXAEDVqK64XNETsXR12VMAADBC7rkEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAIE192QMMMaktYkxD2VPUjs72sicAABiiuuLyqpkRTc1lT1FbGitlTwAAMKi64vLA1ohmcQkAUKvccwkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAECa+rIHGGLVmoh1G8ueojY0ViJaGsueAgBgiOqKy1nzI7r7yp6i+nW2Ryw4T1wCAFWnuuJyRU/E0tVlTwEAwAi55xIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA06XH59a9/PT70oQ9lXxYAgBqQ+vWPDz74YMybNy+6uroyLwsAQI1Ie+dy06ZNcfbZZ8eXv/zlmDx5ctZlAQCoIWlxefXVV8dDDz0UkyZNit/+9rexYcOGrEsDAFAjUuJy3bp1cdFFF8XkyZPj8ccfjyuuuCLe/va3xwsvvLDF4wcGBqKvr2/IAwCA2pcSlzfffHM8//zzceedd8bFF18cd9xxR/T398fPf/7zLR4/Z86caGlpGXx0dHRkjAEAQMlS4vLJJ5+M6dOnR1tbW0RE1NfXx9SpU2Pp0qVbPH727NnR29s7+Oju7s4YAwCAkqX8tviECRM2+wj88ccfj2OOOWaLx1cqlahUKhk/GgCAKpLyzuWJJ54YS5YsiauvvjqefPLJuPLKK6Orqys++tGPZlweAIAakRKX++23X/z+97+P66+/Pg499ND40Y9+FL/+9a/dSwkAsIdJ+yPqb3vb22Lx4sVZlwMAoAb5bnEAANKISwAA0ohLAADSiEsAANKISwAA0ohLAADSiEsAANKISwAA0ohLAADSpH1DT4pJbRFjGsqeovp1tpc9AQDAFlVXXF41M6KpuewpakNjpewJAAA2U11xeWBrRLO4BACoVe65BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAIE192QMMsWpNxLqNZU9RHRorES2NZU8BADAs1RWXs+ZHdPeVPUX5OtsjFpwnLgGAmlNdcbmiJ2Lp6rKnAABghNxzCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAEAacQkAQBpxCQBAGnEJAECa+rIHGGJSW8SYhrKnKF9ne9kTAACMSHXF5VUzI5qay56iOjRWyp4AAGDYqisuD2yNaBaXAAC1yj2XAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApKkve4AhVq2JWLex7Cl2jcZKREtj2VMAAKSqrricNT+iu6/sKUZfZ3vEgvPEJQCw26muuFzRE7F0ddlTAAAwQu65BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAIM2oxOXxxx8f11133WhcGgCAKpYel7/85S/jT3/6U/ZlAQCoAalxuWbNmvjqV78ahx12WOZlAQCoEfWZF/vqV78aJ598crzwwgvbPG5gYCAGBgYGn/f19WWOAQBASdLeubzzzjvjz3/+c3zve9/b7rFz5syJlpaWwUdHR0fWGAAAlCglLv/zn//EOeecEz/+8Y+jqalpu8fPnj07ent7Bx/d3d0ZYwAAULKUj8W/853vxLRp0+LEE0/coeMrlUpUKpWMHw0AQBVJicsbbrghVq9eHa9+9asjImL9+vXx61//Ou69996YN29exo8AAKAGpMTl3/72t9i4cePg86997Wsxffr0OOOMMzIuDwBAjUiJywkTJgx5vu+++0ZbW1u0tbVlXB4AgBqR+qeIXubbeQAA9ky+WxwAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA0o/INPSM2qS1iTEPZU4y+zvayJwAAGBXVFZdXzYxoai57il2jsVL2BAAA6aorLg9sjWjeQ+ISAGA35J5LAADSiEsAANKISwAA0ohLAADSiEsAANKISwAA0ohLAADSiEsAANKISwAA0ohLAADSiEsAANKISwAA0tSXPcAQq9ZErNtY9hS7RmMloqWx7CkAAFJVV1zOmh/R3Vf2FKOvsz1iwXniEgDY7VRXXK7oiVi6uuwpAAAYIfdcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJCmvuwBhpjUFjGmoewpRl9ne9kTAACMiuqKy6tmRjQ1lz3FrtFYKXsCAIB01RWXB7ZGNO8hcQkAsBtyzyUAAGnEJQAAacQlAABpxCUAAGnEJQAAacQlAABpxCUAAGnEJQAAacQlAABpxCUAAGnEJQAAacQlAABp6sseYIhVayLWbSx7itHXWIloaSx7CgCAdNUVl7PmR3T3lT3F6Opsj1hwnrgEAHZL1RWXK3oilq4uewoAAEbIPZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApEmLy4ULF8bkyZOjvr4+jjjiiHjkkUeyLg0AQI1Iictly5bFmWeeGZdeemmsXLkyDj300DjrrLMyLg0AQA1JictHHnkkLr300vjEJz4RBxxwQJx77rlx//33Z1waAIAakvLd4jNmzBjy/LHHHotDDjkk49IAANSQlLj8/zZs2BCXXXZZfOUrX9nqMQMDAzEwMDD4vK+vL3sMAABKkP7b4hdddFE0NjZu857LOXPmREtLy+Cjo6MjewwAAEqQGpeLFi2KuXPnxg033BB77733Vo+bPXt29Pb2Dj66u7szxwAAoCRpH4svX748Tj/99Jg7d25MmTJlm8dWKpWoVCpZPxoAgCqREpcvvPBCzJgxI0466aQ4+eSTY926dRER0djYGHV1dRk/AgCAGpDysfjtt98eS5Ysifnz50dTU9Pg4/HHH8+4PAAANSLlncuTTjopiqLIuBQAADXMd4sDAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJBGXAIAkEZcAgCQRlwCAJAm5esf00xqixjTUPYUo6uzvewJAABGTXXF5VUzI5qay55i9DVWyp4AAGBUVFdcHtga0bwHxCUAwG7KPZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkqS97gCFWrYlYt7HsKQAAqltjJaKlsewptqi64nLW/IjuvrKnAACoXp3tEQvOE5c7ZEVPxNLVZU8BAMAIuecSAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDTiEgCANOISAIA04hIAgDT1ZQ8wxKS2iDENZU8BAFC9OtvLnmCbqisur5oZ0dRc9hQAANWtsVL2BFtVXXF5YGtEs7gEAKhV7rkEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACCNuAQAII24BAAgjbgEACBNfdkDREQURREREX19fSVPAgDAlrzcaS9329ZURVw+++yzERHR0dFR8iQAAGxLf39/tLS0bPW/V0Vctra2RkTEE088sc1h2VxfX190dHREd3d3NDc3lz1OzbF+O8f6jZy12znWb+dYv5Hbk9euKIro7++Pgw46aJvHVUVc7rXXS7d+trS07HH/Q2Vpbm62djvB+u0c6zdy1m7nWL+dY/1Gbk9dux15E9Av9AAAkEZcAgCQpirislKpxEUXXRSVSqXsUWqOtds51m/nWL+Rs3Y7x/rtHOs3ctZu++qK7f0+OQAA7KCqeOcSAIDdg7gEACCNuAQA+H+ee+65+Pvf/x5r164te5SaJC6Brerp6YnOzs5YsWLFDh3/4Q9/OOrq6gYfxx133OgOyG5r4cKFMXny5Kivr48jjjgiHnnkke2eY/8NJZBG5je/+U1MmjQpzjrrrJgwYUL85je/2e459t5QuyQuH3744Zg2bVqMGzcuLrjggu1+J2VExE033RQTJ06Mgw46KG688cZdMGV1GsnaTZ06dcgmP+uss3bBpNVruIF01113xRve8IZoa2uLyy+/fHSHq2I9PT0xY8aMHV63iIh//OMf8dBDD8XatWtj7dq1sXDhwtEbsMqNJI7svZcsW7YszjzzzLj00ktj5cqVceihh+7Qv2P23/+MJJDsv4je3t744he/GH/961/joYceirlz58YFF1yw3fPsvVcoRtl//vOfYtKkScU555xTLF26tDjhhBOKn/3sZ9s856GHHioaGhqK+fPnFw8++GDxute9rnj00UdHe9SqM5K1e/7554uxY8cWzzzzTLF27dpi7dq1xfr163fRxNVn9erVxdFHH11ERLF8+fLtHv/MM88Uzc3NxcUXX1z861//Ko488shi0aJFoz9oFXrve99b/OhHP9rhtXvyySeL8ePHj/5gNWDp0qXFuHHjil/96lfF008/XXz84x8vjjnmmG2eY+/9z2233Vb85Cc/GXy+aNGi4lWvetU2z7H//ue5554r2traiq6urqIoiuLaa68tJk6cuM1z7L+XPPHEE8UvfvGLweddXV3Fvvvuu81z7L3NjXpc3nLLLcW4ceOK559/viiKonjggQeKt73tbds85/zzzy8+8IEPDD7/4Q9/WHzjG98Y1Tmr0UjW7u677y6mT5++K8arCcMNpCuuuKJ4/etfX2zatKkoiqK49dZbi0996lOjPGV1+ve//10URbHDa3fzzTcX+++/f/Ga17ymGDt2bHHqqacWa9asGeUpq9NI4sje27of//jHxdSpU7d5jP33PyMJJPtvcxs2bCjOOOOM4tOf/vQ2j7P3NjfqH4t3dXXF9OnTY+zYsRHx0ke2S5Ys2e4573nPewafv+Utb4n77rtvVOesRiNZu3vvvTeefPLJ2H///ePVr351nHvuuTEwMLArxq1K8+fPjy996Us7fHxXV1e8+93vjrq6uojYc/deRERnZ+ewjn/00Ufj8MMPj9/97ndxzz33xPLly2P27NmjNF11mzFjRpx99tmDzx977LE45JBDtnmOvbdlGzZsiMsuuyy+8IUvbPM4++9/Ojo64lOf+lRERLz44otxxRVXxMknn7zNc+y/obq6umL8+PHxxz/+Ma688sptHmvvbW7U47Kvr2/I/0nV1dXFmDFjtnmD8SvPaW5ujqeeempU56xGI1m7xx57LN7+9rfH3XffHX/605/ijjvuiCuuuGJXjFuVhhtI9t7IzZ49O+644444/PDD401velN8//vfj5tuuqnssUq3o3Fk723ZRRddFI2Njdu959L+29xwAsn+G2rq1Klx++23xyGHHGLvjcCox2V9ff1mX5G0zz77xPr163f4nO0dv7saydpdffXVceONN8Zhhx0WRx99dHzrW9/a4zf5cNh7edrb2+PZZ5/do985j9jxOLL3Nrdo0aKYO3du3HDDDbH33nsP61z7b3iBZP8NVVdXF0cddVRcf/31cfPNN8dzzz23w+fae7sgLltbW2P16tVDXuvv74+GhoYdPmd7x++uRrJ2r9Te3h4rV67MHm23Ze+N3Kmnnhp333334PPFixfHAQccsEd//+5w4sjeG2r58uVx+umnx9y5c2PKlCnbPd7+29xwAsn+e8ldd9015LfDGxoaoq6uLvbaa+u5ZO9tbtTjctq0abF48eLB58uXL4+BgYFobW3d4XPuv//+eM1rXjOqc1ajkazdW9/61uju7h58vnjx4pg4ceKozrk7sfe2r6+vL1588cXNXn/Tm94UX/7yl+Puu++OW2+9NWbPnh3nnntuCRNWh+HGkb33Py+88ELMmDEjTjrppDj55JNj3bp1sW7duiiKwv7bASMJJPvvJYceemj89Kc/jZ/+9KfR3d0dF154Ybz//e+P5uZme284Rvs3hl588cVi//33H/wTOmeddVYxY8aMoiiKYu3atcXGjRs3O+eBBx4oGhsbiwcffLDo7+8vjjjiiOIHP/jBaI9adUaydp///OeLD37wg8U999xTXHfddUVjY2Nx3XXX7dK5q1G84jeee3t7iw0bNmx23OrVq4t99tmnuOOOO4oNGzYUxx9/fDFr1qxdOGn1eeXaTZw4sbjllls2O27Dhg3F5z73uaKxsbEYP358cfHFFxcvvvjirhu0iqxfv76YMmVKMXPmzKK/v3/wsWnTJntvB9x6661FRGz2WL58uf23A5566qmiubm5+MlPflI88cQTxWc+85ni+OOPL4rCv3074vbbby+mTJlSNDU1FaecckrxzDPPFEXh377hGPW4LIqiWLhwYTF27Nhiv/32K/bff//in//850s/PKK4//77t3jOhRdeWDQ0NBTNzc3FUUcdtcf+rcbhrt3atWuLj3zkI8WrXvWqYuLEicW8efN28cTVaUcDqShe+rMne++9dzFu3Liis7OzePrpp3fNkOw2RhJHRWHvkWe4gVQU9h956opiB77yJcHTTz8d9913X0yfPj3222+/HTpnyZIlsXLlynjnO9+5R9778bKRrB07Z/ny5fHoo4/GscceG/vuu2/Z47AHsfcok/1Hhl0WlwAA7P52yXeLAwCwZxCXAACkEZcAAKQRlwAApBGXAACkEZcAAKQRlwAApBGXAACkEZcAAKT5P4SOPNRj9+HiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x650 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "## shap\n",
    "import shap\n",
    "\n",
    "Y = CRCtrain['ill']\n",
    "Y\n",
    "#训练模型\n",
    "XGBmodel=clfXGB\n",
    "XGBmodel.fit(CRCtrainX,CRCtrainY)\n",
    "explainer = shap.Explainer(XGBmodel)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "\n",
    "shap.plots.bar(shap_values, max_display=10)\n",
    "shap.plots.bar(shap_values.cohorts(2).abs.mean(0))\n",
    "\n",
    "shap.plots.heatmap(shap_values[1:100])\n",
    "shap.plots.waterfall(shap_values[11]) # For the first observation\n",
    "\n",
    "shap.summary_plot(shap_values, CRCtrainX)\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "\n",
    "# 创建SVM分类器对象\n",
    "svmclf = svm.SVC()\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "cvSFS= StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=100)\n",
    "print('roc_auc={}'.format(cross_val_score(svmclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(svmclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(svmclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(svmclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# 使用训练集进行模型训练\n",
    "svmclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = svmclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = svmclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置字体为Arial\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.figure(figsize=(6, 8), dpi=300)  # 这里的参数表示宽度和高度都为6英寸，输出分辨率为300 DPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ac7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# 创建 StratifiedShuffleSplit 对象\n",
    "cvSFS = StratifiedShuffleSplit(n_splits=5, test_size=0.35, random_state=100)\n",
    "\n",
    "# 初始化空列表，用于存储每个折叠的ROC曲线数据\n",
    "roc_data = []\n",
    "\n",
    "# 设置图像大小\n",
    "plt.figure(figsize=(6, 6))  # 设置宽度为8英寸，高度为6英寸\n",
    "\n",
    "# 循环遍历每个折叠\n",
    "for train_index, test_index in cvSFS.split(CRCtrainX, CRCtrainY):\n",
    "    X_train, X_test = CRCtrainX.iloc[train_index], CRCtrainX.iloc[test_index]\n",
    "    y_train, y_test = CRCtrainY.iloc[train_index], CRCtrainY.iloc[test_index]\n",
    "\n",
    "    # 训练SVM模型\n",
    "    svmclf.fit(X_train, y_train)\n",
    "\n",
    "    # 获取决策函数值\n",
    "    decision_values = svmclf.decision_function(X_test)\n",
    "\n",
    "    # 计算 ROC 曲线的各个点\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, decision_values)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # 将ROC曲线数据添加到列表中\n",
    "    roc_data.append((fpr, tpr, roc_auc))\n",
    "\n",
    "# 创建一个颜色列表，可以根据需要添加更多颜色\n",
    "colors = ['#008891', '#c06c84', '#222831', '#c61951', '#e43a19']\n",
    "\n",
    "# 绘制每个折叠的ROC曲线\n",
    "for i, (fpr, tpr, roc_auc) in enumerate(roc_data):\n",
    "    color = colors[i % len(colors)]  # 通过取余来循环使用颜色列表\n",
    "    plt.plot(fpr, tpr, lw=1, linestyle='--', color=color, label='ROC curve (Fold %d) (area = %0.2f)' % (i + 1, roc_auc))\n",
    "\n",
    "# 绘制平均ROC曲线\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.mean([np.interp(mean_fpr, fpr, tpr) for fpr, tpr, _ in roc_data], axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "# 添加阴影\n",
    "plt.fill_between(mean_fpr, 0, mean_tpr, alpha=0.2, color='#dcdddd')\n",
    "\n",
    "# 绘制平均ROC曲线\n",
    "plt.plot(mean_fpr, mean_tpr, color='#c53d43', lw=2, linestyle='-', label='Mean ROC (area = %0.2f)' % mean_auc)\n",
    "\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot([0, 1], [0, 1], color='#294a66', lw=2, linestyle='--')\n",
    "# 设置轴线宽度\n",
    "ax = plt.gca()\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['right'].set_linewidth(2)\n",
    "ax.spines['top'].set_linewidth(2)\n",
    "# 设置轴线刻度线的宽度和长度\n",
    "ax.tick_params(axis='x', which='both', width=2, length=6)\n",
    "ax.tick_params(axis='y', which='both', width=2, length=6)\n",
    "\n",
    "# 设置轴线标签和标题的字体和粗细\n",
    "plt.ylabel('Sensitivity', fontsize=20, fontweight='bold')\n",
    "plt.xlabel('1-Specificity', fontsize=20, fontweight='bold')\n",
    "plt.xticks(fontsize=17, fontweight='bold')\n",
    "plt.yticks(fontsize=17, fontweight='bold')\n",
    "plt.title('ROC curve of training cohort - Cross Validation', fontsize=21, fontweight='bold')\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 创建 FontProperties 对象并设置字体为加粗\n",
    "font = FontProperties()\n",
    "font.set_weight('bold')\n",
    "font.set_size(14.5)  # 设置字体大小\n",
    "# 设置图例并传递 FontProperties 对象\n",
    "plt.legend(prop=font, loc=\"lower right\")\n",
    "\n",
    "\n",
    "# 保存图像并设置输出分辨率\n",
    "plt.savefig(\"SVM.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(CRCtestY, y_pred)\n",
    "auc_value = auc(fpr, tpr)\n",
    "print(\"AUC:\", auc_value)\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = svmclf.decision_function(CRCtestX)  # 使用decision_function获取概率\n",
    "\n",
    "# 计算ROC曲线\n",
    "fpr, tpr, thresholds = roc_curve(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = svmclf.predict(CRCtestX)\n",
    "\n",
    "# 计算AUC\n",
    "y_pred_prob = svmclf.decision_function(CRCtestX)\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 计算准确性\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "confusion = confusion_matrix(CRCtestY, y_pred)\n",
    "# 计算特异性\n",
    "specificity = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1])\n",
    "\n",
    "# 计算敏感性\n",
    "sensitivity = confusion[1, 1] / (confusion[1, 0] + confusion[1, 1])\n",
    "\n",
    "print(f\"AUC: {roc_auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.2f}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = svmclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "y_pred_prob\n",
    "\n",
    "roc_auc\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = svmclf.decision_function(CRCtestX)  # 使用decision_function获取概率\n",
    "\n",
    "# 计算ROC曲线\n",
    "fpr, tpr, thresholds = roc_curve(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# 设置图像大小\n",
    "plt.figure(figsize=(6, 6))\n",
    "# 绘制ROC曲线\n",
    "plt.plot(fpr, tpr, color='#415f9d', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='#294a66', lw=2, linestyle='--')\n",
    "\n",
    "# 添加阴影\n",
    "plt.fill_between(fpr, tpr, 0, alpha=0.2, color='#dcdddd')  # 添加阴影\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['right'].set_linewidth(2)\n",
    "ax.spines['top'].set_linewidth(2)\n",
    "# 设置轴线刻度线的宽度和长度\n",
    "ax.tick_params(axis='x', which='both', width=2, length=6)\n",
    "ax.tick_params(axis='y', which='both', width=2, length=6)\n",
    "\n",
    "\n",
    "plt.title('ROC curve for validation cohort', fontsize=21, fontweight='bold')\n",
    "# 设置轴线标签和标题的字体和粗细从\n",
    "plt.ylabel('Sensitivity ', fontsize=20, fontweight='bold')\n",
    "plt.xlabel('1-Specificity ', fontsize=20, fontweight='bold')\n",
    "plt.xticks(fontsize=17, fontweight='bold')\n",
    "plt.yticks(fontsize=17, fontweight='bold')\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 创建 FontProperties 对象并设置字体大小\n",
    "font = FontProperties()\n",
    "font.set_weight('bold')\n",
    "font.set_size(17)  # 设置字体大小\n",
    "\n",
    "# 设置图例并传递 FontProperties 对象\n",
    "plt.legend(prop=font, loc=\"lower right\")\n",
    "\n",
    "accuracy_text = f'Accuracy  : 0.78'\n",
    "sensitivity_text = f'Sensitivity: 0.80'\n",
    "specificity_text = f'Specificity: 0.77'\n",
    "\n",
    "# 添加文本标签到图例位置\n",
    "plt.text(0.45, 0.35, accuracy_text, fontsize=18, fontweight='bold')\n",
    "plt.text(0.45, 0.27, sensitivity_text, fontsize=18, fontweight='bold')\n",
    "plt.text(0.45, 0.19, specificity_text, fontsize=18, fontweight='bold')\n",
    "\n",
    "\n",
    "# 保存图像并设置输出分辨率\n",
    "# 保存图像并设置输出分辨率\n",
    "plt.savefig(\"SVM_ROC-voc.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 获取模型在测试集上的预测标签\n",
    "y_pred = svmclf.predict(CRCtestX)\n",
    "\n",
    "# 计算AUC\n",
    "y_pred_prob = svmclf.predict(CRCtestX)  # 获取决策函数值作为预测概率\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 计算Accuracy\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算Confusion Matrix（混淆矩阵）\n",
    "conf_matrix = confusion_matrix(CRCtestY, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# 计算Specificity和Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 打印结果\n",
    "print(\"AUC:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "\n",
    "\n",
    "explainer = shap.KernelExplainer(svmclf.predict,CRCtrainX)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "shap.summary_plot(shap_values, CRCtrainX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ec27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 创建朴素贝叶斯分类器对象\n",
    "NBclf = GaussianNB(var_smoothing=1e-9)\n",
    "print('roc_auc={}'.format(cross_val_score(NBclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(NBclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(NBclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(NBclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# 使用训练集进行模型训练\n",
    "NBclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = NBclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "NBclf.fit(CRCtrainX, CRCtrainY)\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = NBclf.predict_proba(CRCtestX)[:, 1]  # 使用predict_proba获取概率\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 获取模型在测试集上的预测标签\n",
    "y_pred = NBclf.predict(CRCtestX)\n",
    "\n",
    "# 计算Accuracy\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算Confusion Matrix（混淆矩阵）\n",
    "conf_matrix = confusion_matrix(CRCtestY, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# 计算Specificity和Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 打印结果\n",
    "print(\"AUC:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = NBclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "\n",
    "explainer = shap.KernelExplainer(NBclf.predict,CRCtrainX)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "shap.summary_plot(shap_values, CRCtrainX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#创建KNN分类器对象\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=5)\n",
    "print('roc_auc={}'.format(cross_val_score(KNNclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(KNNclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(KNNclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(KNNclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "# 使用训练集进行模型训练\n",
    "KNNclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = KNNclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = KNNclf.predict_proba(CRCtestX)[:, 1]  # 使用predict_proba获取概率\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 获取模型在测试集上的预测标签\n",
    "y_pred = KNNclf.predict(CRCtestX)\n",
    "\n",
    "# 计算Accuracy\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算Confusion Matrix（混淆矩阵）\n",
    "conf_matrix = confusion_matrix(CRCtestY, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# 计算Specificity和Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 打印结果\n",
    "print(\"AUC:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "NBclf.fit(CRCtrainX, CRCtrainY)\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = KNNclf.predict_proba(CRCtestX)[:, 1]  # 使用predict_proba获取概率\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 获取模型在测试集上的预测标签\n",
    "y_pred = KNNclf.predict(CRCtestX)\n",
    "\n",
    "# 计算Accuracy\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算Confusion Matrix（混淆矩阵）\n",
    "conf_matrix = confusion_matrix(CRCtestY, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# 计算Specificity和Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 打印结果\n",
    "print(\"AUC:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = KNNclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "\n",
    "explainer = shap.KernelExplainer(KNNclf.predict,CRCtrainX)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "shap.summary_plot(shap_values, CRCtrainX)\n",
    "# LGB\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 重要参数：\n",
    "lgb_model = LGBMClassifier()\n",
    "\n",
    "print('roc_auc={}'.format(cross_val_score(lgb_model,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(lgb_model,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(lgb_model,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# 使用训练集进行模型训练\n",
    "lgb_model.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = lgb_model.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "explainer = shap.Explainer(lgb_model)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Adaclf = AdaBoostClassifier(n_estimators=450, random_state=100)\n",
    "\n",
    "print('roc_auc={}'.format(cross_val_score(Adaclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(Adaclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(Adaclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(Adaclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# 使用训练集进行模型训练\n",
    "Adaclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = Adaclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "Adaclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型对测试集进行预测\n",
    "predictions = Adaclf.predict(CRCtestX)\n",
    "\n",
    "# 计算AUC\n",
    "auc = roc_auc_score(CRCtestY, predictions)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(CRCtestY, predictions)\n",
    "\n",
    "# 计算混淆矩阵，以便计算特异性和敏感性\n",
    "conf_matrix = confusion_matrix(CRCtestY, predictions)\n",
    "\n",
    "# 计算特异性\n",
    "specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "\n",
    "# 计算敏感性\n",
    "sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "\n",
    "# 打印结果\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = Adaclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "# CatBoost\n",
    "# pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "Catclf = CatBoostClassifier(iterations=500, learning_rate=0.05, depth=5, verbose=100)\n",
    "\n",
    "\n",
    "print('roc_auc={}'.format(cross_val_score(Catclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(Catclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(Catclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(Catclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "# 使用训练集进行模型训练\n",
    "Catclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = Catclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = Catclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CRCtest['ill'] = pd.Categorical(CRCtest['ill']).codes \n",
    "#将 '对照' 列转换为整数编码，并将结果存储回 '对照' 列。CRC2['类别'] = pd.Categorical(IBD_2['类别']).codes\n",
    "#提取特征列\n",
    "CRCtestX=CRCtest.iloc[:,0:54] ##定义x\n",
    "#提取标签列\n",
    "CRCtestY=CRCtest.iloc[:,54]##定义标签\n",
    "\n",
    "\n",
    "# pip install xgboost \n",
    "import xgboost as xgb\n",
    "\n",
    "xgb.__version__\n",
    "## XGBClassifier (未调参)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#模型训练\n",
    "clfXGB=XGBClassifier(random_state=200)\n",
    "#分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(CRCtrainX,CRCtrainY,test_size=0.2,random_state=100)\n",
    "#在使用 ShuffleSplit 进行交叉验证时，通常需要指定 test_size 或 train_size，其中至少一个必须是非空的。\n",
    "\n",
    "#例如，如果指定 test_size=0.3，则将数据集划分为 70% 的训练集和 30% 的测试集。\n",
    "\n",
    "#每次迭代时，ShuffleSplit 都会重新随机重排数据集，并将其划分为训练集和测试集。\n",
    "\n",
    "#最后，可以通过计算多个迭代的平均性能，来评估模型的泛化能力和稳定性。\n",
    "\n",
    "# StratifiedShuffleSplit 是一种交叉验证策略，用于将数据集划分为训练集和测试集。与 ShuffleSplit 类似，StratifiedShuffleSplit 也是通过对数据集进行随机重排，然后将数据集划分为多个训练集和测试集，以测试模型在不同的训练集和测试集上的性能。不同之处在于 StratifiedShuffleSplit 会保证每个划分中，训练集和测试集中的类别分布是一致的，从而避免了因类别分布不均衡而导致的模型偏差或方差问题。\n",
    "\n",
    "# sklearn.metrics.SCORERS.keys()返回一个包含所有可用的scoring函数名称的列表。这些名称可以作为scoring参数传递给cross_val_score()和GridSearchCV()等函数\n",
    "# from sklearn.metrics import SCORERS\n",
    "\n",
    "# print(SCORERS.keys())\n",
    "\n",
    "# 'accuracy'：准确率；\n",
    "# \n",
    "# 'balanced_accuracy'：平衡准确率；\n",
    "# \n",
    "# 'top_k_accuracy'：top_k准确率，k可以通过参数进行设置；\n",
    "# \n",
    "# 'average_precision'：平均准确率；\n",
    "# \n",
    "# 'neg_brier_score'：负Brier分数；\n",
    "# \n",
    "# 'f1'：F1分数，综合考虑了精确率和召回率；\n",
    "# \n",
    "# 'f1_micro'：微平均F1分数；\n",
    "# \n",
    "# 'f1_macro'：宏平均F1分数；\n",
    "# \n",
    "# 'f1_weighted'：加权平均F1分数，按照样本数量加权；\n",
    "# \n",
    "# 'f1_samples'：样本平均F1分数，针对多标签分类；\n",
    "# \n",
    "# 'neg_log_loss'：负对数似然损失，适用于概率模型；\n",
    "# \n",
    "# 'precision'：精确率；\n",
    "# \n",
    "# 'recall'：召回率；\n",
    "# \n",
    "# 'roc_auc'：ROC曲线下的面积；\n",
    "# \n",
    "# 'roc_auc_ovo'：多类别ROC曲线下的面积（一对多）；\n",
    "# \n",
    "# 'roc_auc_ovr'：多类别ROC曲线下的面积（一对剩余）；\n",
    "# \n",
    "# 'balanced_accuracy'：平衡准确率。\n",
    "# \n",
    "# 需要注意的是，有些指标是多类别分类特有的，例如roc_auc_ovo和roc_auc_ovr，可以处理多类别分类的问题。\n",
    "\n",
    "clfXGB.fit(CRCtrainX,CRCtrainY)\n",
    "# 预测概率\n",
    "CRCtrainY_prob = clfXGB.predict_proba(CRCtrainX)[:, 1]\n",
    "\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#balanced accuracy\n",
    "print('准确率={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='balanced_accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('roc_auc={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "\n",
    "print('F1值率{}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='f1_weighted',cv=cvSFS).mean()))\n",
    "\n",
    "## 调参\n",
    "import hyperopt\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, partial, tpe\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    clf=XGBClassifier(n_estimators= int(params['n_estimators']),#以字典的结构传入，int：参数取值为整数\n",
    "                      learning_rate=int(params['learning_rate']),\n",
    "                      max_depth=int(params['max_depth']),                   \n",
    "                      random_state=100)#不需要调的就直接输入固定值  \n",
    "     \n",
    "    cv=StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=100)#定义交叉验证\n",
    "    \n",
    "    res = cross_val_score(clf,                                        \n",
    "                          CRCtrainX,CRCtrainY, #输入交叉验证训练样本 \n",
    "                          scoring='roc_auc',\n",
    "                          cv=cv,\n",
    "                          #error_score=\"raise\",\n",
    "                          ).mean() #如果交叉验证中算法执行报错，告诉错误理由\n",
    "    \n",
    "\n",
    "    return res \n",
    " \n",
    "spaces = {\"n_estimators\": hp.quniform(\"n_estimators\",25,500,25),#均匀分布的浮点数\n",
    "          \"max_depth\": hp.quniform(\"max_depth\", 1, 10,2),\n",
    "          \"learning_rate\": hp.quniform(\"learning_rate\",0.1,1,0.1)}\n",
    "         \n",
    "                                        \n",
    "\n",
    "#保存送代过程\n",
    "trials=Trials()\n",
    "\n",
    "#设置提前停止\n",
    "early_stop_fn=no_progress_loss(100)  #连续100次损失函数没有下降，就停止模型\n",
    "\n",
    "#定义代理模型\n",
    "params_best2=fmin(hyperopt_objective,\n",
    "                    space=spaces,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=100,\n",
    "                    verbose=True,\n",
    "                    trials=trials,\n",
    "                    early_stop_fn=early_stop_fn,\n",
    "                    rstate=np.random.default_rng(100)#稳定优化参数结果\n",
    "                )     \n",
    "#报错代码段：rstate=RandomState(seed),解决方案：rstate=np.random.default_rng(seed),问题根源：版本问题\n",
    "\n",
    "params_best2\n",
    "\n",
    "clfXGB=XGBClassifier(learning_rate=0.6, max_depth=4, n_estimators=450, random_state=200)\n",
    "clfXGB\n",
    "print('准确率={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "\n",
    "print('roc_auc={}'.format(cross_val_score(clfXGB,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "\n",
    "\n",
    "## shap\n",
    "import shap\n",
    "\n",
    "Y = CRCtrain['ill']\n",
    "Y\n",
    "#训练模型\n",
    "XGBmodel=clfXGB\n",
    "XGBmodel.fit(CRCtrainX,CRCtrainY)\n",
    "explainer = shap.Explainer(XGBmodel)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "\n",
    "shap.plots.bar(shap_values, max_display=10)\n",
    "shap.plots.bar(shap_values.cohorts(2).abs.mean(0))\n",
    "\n",
    "shap.plots.heatmap(shap_values[1:100])\n",
    "shap.plots.waterfall(shap_values[11]) # For the first observation\n",
    "\n",
    "shap.summary_plot(shap_values, CRCtrainX)\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "\n",
    "# 创建SVM分类器对象\n",
    "svmclf = svm.SVC()\n",
    "\n",
    "\n",
    "cvSFS= StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=100)\n",
    "print('roc_auc={}'.format(cross_val_score(svmclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(svmclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(svmclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(svmclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# 使用训练集进行模型训练\n",
    "svmclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = svmclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = svmclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置字体为Arial\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.figure(figsize=(6, 8), dpi=300)  # 这里的参数表示宽度和高度都为6英寸，输出分辨率为300 DPI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85310dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# 创建 StratifiedShuffleSplit 对象\n",
    "cvSFS = StratifiedShuffleSplit(n_splits=5, test_size=0.35, random_state=100)\n",
    "\n",
    "# 初始化空列表，用于存储每个折叠的ROC曲线数据\n",
    "roc_data = []\n",
    "\n",
    "# 设置图像大小\n",
    "plt.figure(figsize=(6, 6))  # 设置宽度为8英寸，高度为6英寸\n",
    "\n",
    "# 循环遍历每个折叠\n",
    "for train_index, test_index in cvSFS.split(CRCtrainX, CRCtrainY):\n",
    "    X_train, X_test = CRCtrainX.iloc[train_index], CRCtrainX.iloc[test_index]\n",
    "    y_train, y_test = CRCtrainY.iloc[train_index], CRCtrainY.iloc[test_index]\n",
    "\n",
    "    # 训练SVM模型\n",
    "    svmclf.fit(X_train, y_train)\n",
    "\n",
    "    # 获取决策函数值\n",
    "    decision_values = svmclf.decision_function(X_test)\n",
    "\n",
    "    # 计算 ROC 曲线的各个点\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, decision_values)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # 将ROC曲线数据添加到列表中\n",
    "    roc_data.append((fpr, tpr, roc_auc))\n",
    "\n",
    "# 创建一个颜色列表，可以根据需要添加更多颜色\n",
    "colors = ['#008891', '#c06c84', '#222831', '#c61951', '#e43a19']\n",
    "\n",
    "# 绘制每个折叠的ROC曲线\n",
    "for i, (fpr, tpr, roc_auc) in enumerate(roc_data):\n",
    "    color = colors[i % len(colors)]  # 通过取余来循环使用颜色列表\n",
    "    plt.plot(fpr, tpr, lw=1, linestyle='--', color=color, label='ROC curve (Fold %d) (area = %0.2f)' % (i + 1, roc_auc))\n",
    "\n",
    "# 绘制平均ROC曲线\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.mean([np.interp(mean_fpr, fpr, tpr) for fpr, tpr, _ in roc_data], axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "# 添加阴影\n",
    "plt.fill_between(mean_fpr, 0, mean_tpr, alpha=0.2, color='#dcdddd')\n",
    "\n",
    "# 绘制平均ROC曲线\n",
    "plt.plot(mean_fpr, mean_tpr, color='#c53d43', lw=2, linestyle='-', label='Mean ROC (area = %0.2f)' % mean_auc)\n",
    "\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot([0, 1], [0, 1], color='#294a66', lw=2, linestyle='--')\n",
    "# 设置轴线宽度\n",
    "ax = plt.gca()\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['right'].set_linewidth(2)\n",
    "ax.spines['top'].set_linewidth(2)\n",
    "# 设置轴线刻度线的宽度和长度\n",
    "ax.tick_params(axis='x', which='both', width=2, length=6)\n",
    "ax.tick_params(axis='y', which='both', width=2, length=6)\n",
    "\n",
    "# 设置轴线标签和标题的字体和粗细\n",
    "plt.ylabel('Sensitivity', fontsize=20, fontweight='bold')\n",
    "plt.xlabel('1-Specificity', fontsize=20, fontweight='bold')\n",
    "plt.xticks(fontsize=17, fontweight='bold')\n",
    "plt.yticks(fontsize=17, fontweight='bold')\n",
    "plt.title('ROC curve of training cohort - Cross Validation', fontsize=21, fontweight='bold')\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 创建 FontProperties 对象并设置字体为加粗\n",
    "font = FontProperties()\n",
    "font.set_weight('bold')\n",
    "font.set_size(14.5)  # 设置字体大小\n",
    "# 设置图例并传递 FontProperties 对象\n",
    "plt.legend(prop=font, loc=\"lower right\")\n",
    "\n",
    "\n",
    "# 保存图像并设置输出分辨率\n",
    "plt.savefig(\"SVM.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(CRCtestY, y_pred)\n",
    "auc_value = auc(fpr, tpr)\n",
    "print(\"AUC:\", auc_value)\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = svmclf.decision_function(CRCtestX)  # 使用decision_function获取概率\n",
    "\n",
    "# 计算ROC曲线\n",
    "fpr, tpr, thresholds = roc_curve(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = svmclf.predict(CRCtestX)\n",
    "\n",
    "# 计算AUC\n",
    "y_pred_prob = svmclf.decision_function(CRCtestX)\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 计算准确性\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "confusion = confusion_matrix(CRCtestY, y_pred)\n",
    "# 计算特异性\n",
    "specificity = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1])\n",
    "\n",
    "# 计算敏感性\n",
    "sensitivity = confusion[1, 1] / (confusion[1, 0] + confusion[1, 1])\n",
    "\n",
    "print(f\"AUC: {roc_auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.2f}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = svmclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "y_pred_prob\n",
    "\n",
    "roc_auc\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = svmclf.decision_function(CRCtestX)  # 使用decision_function获取概率\n",
    "\n",
    "# 计算ROC曲线\n",
    "fpr, tpr, thresholds = roc_curve(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# 设置图像大小\n",
    "plt.figure(figsize=(6, 6))\n",
    "# 绘制ROC曲线\n",
    "plt.plot(fpr, tpr, color='#415f9d', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='#294a66', lw=2, linestyle='--')\n",
    "\n",
    "# 添加阴影\n",
    "plt.fill_between(fpr, tpr, 0, alpha=0.2, color='#dcdddd')  # 添加阴影\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['bottom'].set_linewidth(2)\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "ax.spines['right'].set_linewidth(2)\n",
    "ax.spines['top'].set_linewidth(2)\n",
    "# 设置轴线刻度线的宽度和长度\n",
    "ax.tick_params(axis='x', which='both', width=2, length=6)\n",
    "ax.tick_params(axis='y', which='both', width=2, length=6)\n",
    "\n",
    "\n",
    "plt.title('ROC curve for validation cohort', fontsize=21, fontweight='bold')\n",
    "# 设置轴线标签和标题的字体和粗细从\n",
    "plt.ylabel('Sensitivity ', fontsize=20, fontweight='bold')\n",
    "plt.xlabel('1-Specificity ', fontsize=20, fontweight='bold')\n",
    "plt.xticks(fontsize=17, fontweight='bold')\n",
    "plt.yticks(fontsize=17, fontweight='bold')\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 创建 FontProperties 对象并设置字体大小\n",
    "font = FontProperties()\n",
    "font.set_weight('bold')\n",
    "font.set_size(17)  # 设置字体大小\n",
    "\n",
    "# 设置图例并传递 FontProperties 对象\n",
    "plt.legend(prop=font, loc=\"lower right\")\n",
    "\n",
    "accuracy_text = f'Accuracy  : 0.78'\n",
    "sensitivity_text = f'Sensitivity: 0.80'\n",
    "specificity_text = f'Specificity: 0.77'\n",
    "\n",
    "# 添加文本标签到图例位置\n",
    "plt.text(0.45, 0.35, accuracy_text, fontsize=18, fontweight='bold')\n",
    "plt.text(0.45, 0.27, sensitivity_text, fontsize=18, fontweight='bold')\n",
    "plt.text(0.45, 0.19, specificity_text, fontsize=18, fontweight='bold')\n",
    "\n",
    "\n",
    "# 保存图像并设置输出分辨率\n",
    "# 保存图像并设置输出分辨率\n",
    "plt.savefig(\"SVM_ROC-voc.png\", dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a573e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 获取模型在测试集上的预测标签\n",
    "y_pred = svmclf.predict(CRCtestX)\n",
    "\n",
    "# 计算AUC\n",
    "y_pred_prob = svmclf.predict(CRCtestX)  # 获取决策函数值作为预测概率\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 计算Accuracy\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算Confusion Matrix（混淆矩阵）\n",
    "conf_matrix = confusion_matrix(CRCtestY, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# 计算Specificity和Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 打印结果\n",
    "print(\"AUC:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "\n",
    "\n",
    "explainer = shap.KernelExplainer(svmclf.predict,CRCtrainX)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "shap.summary_plot(shap_values, CRCtrainX)\n",
    "\n",
    "\n",
    "#  GaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 创建朴素贝叶斯分类器对象\n",
    "NBclf = GaussianNB(var_smoothing=1e-9)\n",
    "print('roc_auc={}'.format(cross_val_score(NBclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(NBclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(NBclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(NBclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# 使用训练集进行模型训练\n",
    "NBclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = NBclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "NBclf.fit(CRCtrainX, CRCtrainY)\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = NBclf.predict_proba(CRCtestX)[:, 1]  # 使用predict_proba获取概率\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 获取模型在测试集上的预测标签\n",
    "y_pred = NBclf.predict(CRCtestX)\n",
    "\n",
    "# 计算Accuracy\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算Confusion Matrix（混淆矩阵）\n",
    "conf_matrix = confusion_matrix(CRCtestY, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# 计算Specificity和Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 打印结果\n",
    "print(\"AUC:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = NBclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "\n",
    "explainer = shap.KernelExplainer(NBclf.predict,CRCtrainX)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "shap.summary_plot(shap_values, CRCtrainX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#创建KNN分类器对象\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=5)\n",
    "print('roc_auc={}'.format(cross_val_score(KNNclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(KNNclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(KNNclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(KNNclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "# 使用训练集进行模型训练\n",
    "KNNclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = KNNclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = KNNclf.predict_proba(CRCtestX)[:, 1]  # 使用predict_proba获取概率\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 获取模型在测试集上的预测标签\n",
    "y_pred = KNNclf.predict(CRCtestX)\n",
    "\n",
    "# 计算Accuracy\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算Confusion Matrix（混淆矩阵）\n",
    "conf_matrix = confusion_matrix(CRCtestY, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# 计算Specificity和Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 打印结果\n",
    "print(\"AUC:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "NBclf.fit(CRCtrainX, CRCtrainY)\n",
    "# 获取模型在测试集上的预测概率\n",
    "y_pred_prob = KNNclf.predict_proba(CRCtestX)[:, 1]  # 使用predict_proba获取概率\n",
    "\n",
    "# 计算AUC\n",
    "roc_auc = roc_auc_score(CRCtestY, y_pred_prob)\n",
    "\n",
    "# 获取模型在测试集上的预测标签\n",
    "y_pred = KNNclf.predict(CRCtestX)\n",
    "\n",
    "# 计算Accuracy\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "\n",
    "# 计算Confusion Matrix（混淆矩阵）\n",
    "conf_matrix = confusion_matrix(CRCtestY, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "# 计算Specificity和Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "# 打印结果\n",
    "print(\"AUC:\", roc_auc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = KNNclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "\n",
    "explainer = shap.KernelExplainer(KNNclf.predict,CRCtrainX)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "shap.summary_plot(shap_values, CRCtrainX)\n",
    "# LGB\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 重要参数：\n",
    "lgb_model = LGBMClassifier()\n",
    "\n",
    "print('roc_auc={}'.format(cross_val_score(lgb_model,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(lgb_model,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(lgb_model,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# 使用训练集进行模型训练\n",
    "lgb_model.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = lgb_model.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "explainer = shap.Explainer(lgb_model)\n",
    "shap_values = explainer(CRCtrainX)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Adaclf = AdaBoostClassifier(n_estimators=450, random_state=100)\n",
    "\n",
    "print('roc_auc={}'.format(cross_val_score(Adaclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(Adaclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(Adaclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(Adaclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# 使用训练集进行模型训练\n",
    "Adaclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = Adaclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "Adaclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型对测试集进行预测\n",
    "predictions = Adaclf.predict(CRCtestX)\n",
    "\n",
    "# 计算AUC\n",
    "auc = roc_auc_score(CRCtestY, predictions)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(CRCtestY, predictions)\n",
    "\n",
    "# 计算混淆矩阵，以便计算特异性和敏感性\n",
    "conf_matrix = confusion_matrix(CRCtestY, predictions)\n",
    "\n",
    "# 计算特异性\n",
    "specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "\n",
    "# 计算敏感性\n",
    "sensitivity = conf_matrix[1, 1] / (conf_matrix[1, 0] + conf_matrix[1, 1])\n",
    "\n",
    "# 打印结果\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = Adaclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")\n",
    "\n",
    "# CatBoost\n",
    "# pip install catboost\n",
    "\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "Catclf = CatBoostClassifier(iterations=500, learning_rate=0.05, depth=5, verbose=100)\n",
    "\n",
    "\n",
    "print('roc_auc={}'.format(cross_val_score(Catclf,CRCtrainX,CRCtrainY,scoring='roc_auc',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('准确率={}'.format(cross_val_score(Catclf,CRCtrainX,CRCtrainY,scoring='accuracy',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "print('precision{}'.format(cross_val_score(Catclf,CRCtrainX,CRCtrainY,scoring='precision',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "#正确预测个数的计数：准确率\n",
    "\n",
    "print('recall={}'.format(cross_val_score(Catclf,CRCtrainX,CRCtrainY,scoring='recall',cv=cvSFS).mean()))#通过修改scoring的参数可以修改评分器\n",
    "# 使用训练集进行模型训练\n",
    "Catclf.fit(CRCtrainX, CRCtrainY)\n",
    "\n",
    "# 使用模型进行测试集预测\n",
    "y_pred = Catclf.predict(CRCtestX)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy = accuracy_score(CRCtestY, y_pred)\n",
    "recall = recall_score(CRCtestY, y_pred)\n",
    "precision = precision_score(CRCtestY, y_pred)\n",
    "\n",
    "auc = roc_auc_score(CRCtestY, y_pred)\n",
    "\n",
    "print(f\"AUC: {auc:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 设置bootstrap的迭代次数\n",
    "n_iterations = 1000\n",
    "\n",
    "# 存储每次迭代的AUC值\n",
    "auc_scores = []\n",
    "\n",
    "# 循环进行bootstrap迭代\n",
    "for _ in range(n_iterations):\n",
    "    # 通过有放回抽样创建新的测试集\n",
    "    CRCtestX_bootstrap, CRCtestY_bootstrap = resample(CRCtestX, CRCtestY, random_state=np.random.randint(100))\n",
    "\n",
    "    # 使用模型进行bootstrap样本的预测\n",
    "    y_pred_bootstrap = Catclf.predict(CRCtestX_bootstrap)\n",
    "\n",
    "    # 计算AUC并将其存储\n",
    "    auc_bootstrap = roc_auc_score(CRCtestY_bootstrap, y_pred_bootstrap)\n",
    "    auc_scores.append(auc_bootstrap)\n",
    "\n",
    "# 计算95%置信区间\n",
    "confidence_interval = np.percentile(auc_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"95% Confidence Interval for AUC: {confidence_interval}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233.641px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
